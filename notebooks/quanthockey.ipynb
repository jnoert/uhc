{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Excel file has been successfully converted to 'assets/quanthockey/QuantHockey_2023_reg.csv'.\n"
     ]
    }
   ],
   "source": [
    "## QuantHockey\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Excel file\n",
    "excel_df = pd.read_excel('assets/quanthockey/QuantHockey_2023_reg.xlsx')\n",
    "\n",
    "# Step 2: Save the DataFrame to a CSV file\n",
    "excel_df.to_csv('assets/quanthockey/QuantHockey_2023_reg.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"The Excel file has been successfully converted to 'assets/quanthockey/QuantHockey_2023_reg.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'QuantHockey' tab has been exported to 'assets/quanthockey/QuantHockey_2023_reg.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Excel file\n",
    "excel_file = 'assets/quanthockey/QuantHockey_2023_reg.xlsx'\n",
    "\n",
    "# Step 2: Load the second tab (QuantHockey) into a DataFrame\n",
    "df = pd.read_excel(excel_file, sheet_name='QuantHockey')\n",
    "\n",
    "# Step 3: Save the DataFrame to a CSV file\n",
    "df.to_csv('assets/quanthockey/QuantHockey_2023_reg.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"The 'QuantHockey' tab has been exported to 'assets/quanthockey/QuantHockey_2023_reg.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'info' sheet has been exported to 'assets/quanthockey/info_2023_reg.csv'.\n",
      "The 'QuantHockey' sheet has been exported to 'assets/quanthockey/QuantHockey_2023_reg.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Excel file\n",
    "excel_file = 'assets/quanthockey/QuantHockey_2023_reg.xlsx'\n",
    "\n",
    "# Step 2: Load both sheets into separate DataFrames\n",
    "sheets = pd.read_excel(excel_file, sheet_name=None)\n",
    "\n",
    "# Step 3: Export each sheet to a separate CSV file\n",
    "for sheet_name, df in sheets.items():\n",
    "    # Create the output file path, using the sheet name in the filename\n",
    "    output_file = f'assets/quanthockey/{sheet_name}_2023_reg.csv'\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Print confirmation\n",
    "    print(f\"The '{sheet_name}' sheet has been exported to '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The header row has been removed and saved to 'assets/quanthockey/QuantHockey_2023_reg_no_header.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file, skipping the header row\n",
    "df = pd.read_csv('assets/quanthockey/QuantHockey_2023_reg.csv', header=None)\n",
    "\n",
    "# Step 2: Save the DataFrame back to the CSV file without the header\n",
    "df.to_csv('assets/quanthockey/QuantHockey_2023_reg_no_header.csv', index=False, header=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"The header row has been removed and saved to 'assets/quanthockey/QuantHockey_2023_reg_no_header.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Excel file with multi-row headers has been saved to 'assets/quanthockey/QuantHockey_2023_reg_with_headers.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Excel file with multi-row headers\n",
    "excel_file = 'assets/quanthockey/QuantHockey_2023_reg.xlsx'\n",
    "\n",
    "# Step 2: Read the Excel file with the first two rows as headers\n",
    "df = pd.read_excel(excel_file, sheet_name='QuantHockey', header=[0, 1])\n",
    "\n",
    "# Step 3: Flatten the multi-index columns by concatenating the two header rows\n",
    "df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "# Step 4: Add a new column titled 'season' as the first column and fill it with '2023'\n",
    "df.insert(0, 'season', '2023')\n",
    "\n",
    "# Step 4: Save the DataFrame to a CSV file\n",
    "df.to_csv('assets/quanthockey/QuantHockey_2023_reg_with_headers.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"The Excel file with multi-row headers has been saved to 'assets/quanthockey/QuantHockey_2023_reg_with_headers.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#START FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405584.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405584.csv' with a new 'playoff' and 'season' column.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405587.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405587.csv' with a new 'playoff' and 'season' column.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405591.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405591.csv' with a new 'playoff' and 'season' column.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405595.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405595.csv' with a new 'playoff' and 'season' column.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405598.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405598.csv' with a new 'playoff' and 'season' column.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405602.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405602.csv' with a new 'playoff' and 'season' column.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405606.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405606.csv' with a new 'playoff' and 'season' column.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405609.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405609.csv' with a new 'playoff' and 'season' column.\n",
      "All CSV files have been merged and saved to 'assets/quanthockey/QuantHockey_2023p_merged.csv'.\n"
     ]
    }
   ],
   "source": [
    "## FIRST ATTEMPT AT PULLING TOGETHER THE 2024 PLAYOFF FILES\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# List of Excel files to process\n",
    "excel_files = [\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405584.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405587.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405591.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405595.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405598.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405602.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405606.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405609.xlsx'\n",
    "]\n",
    "\n",
    "# Loop through each file\n",
    "for file in excel_files:\n",
    "    # Step 1: Load the Excel file with multi-row headers\n",
    "    df = pd.read_excel(file, sheet_name='QuantHockey', header=[0, 1])\n",
    "\n",
    "    # Step 2: Flatten the multi-index columns by concatenating the two header rows\n",
    "    df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "    # Step 3: Add a new column titled 'season' as the first column and fill it with '2023'\n",
    "    df.insert(0, 'playoff', '2024')\n",
    "    df.insert(1, 'season', '2023')\n",
    "\n",
    "    # Step 4: Construct the output CSV file name\n",
    "    output_file = file.replace('.xlsx', '.csv')\n",
    "\n",
    "    # Step 5: Save the DataFrame to a CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Print confirmation\n",
    "    print(f\"The Excel file '{file}' has been processed and saved to '{output_file}' with a new 'playoff' and 'season' column.\")\n",
    "\n",
    "# List of CSV files to merge\n",
    "csv_files = [\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405584.csv',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405587.csv',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405591.csv',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405595.csv',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405598.csv',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405602.csv',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405606.csv',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405609.csv'\n",
    "]\n",
    "\n",
    "# Step 1: Merge all CSV files into one DataFrame\n",
    "merged_df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "\n",
    "# Step 2: Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('assets/quanthockey/QuantHockey_2023p_merged.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"All CSV files have been merged and saved to 'assets/quanthockey/QuantHockey_2023p_merged.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405584.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405584_with_headers.csv' with new 'season' and 'playoff' columns.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405587.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405587_with_headers.csv' with new 'season' and 'playoff' columns.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405591.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405591_with_headers.csv' with new 'season' and 'playoff' columns.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405595.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405595_with_headers.csv' with new 'season' and 'playoff' columns.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405598.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405598_with_headers.csv' with new 'season' and 'playoff' columns.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405602.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405602_with_headers.csv' with new 'season' and 'playoff' columns.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405606.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405606_with_headers.csv' with new 'season' and 'playoff' columns.\n",
      "The Excel file 'assets/quanthockey/xlsx/QuantHockey_1723405609.xlsx' has been processed and saved to 'assets/quanthockey/xlsx/QuantHockey_1723405609_with_headers.csv' with new 'season' and 'playoff' columns.\n",
      "All processed CSV files have been merged and saved to 'assets/quanthockey/QuantHockey_2023_playoffs_merged.csv'.\n"
     ]
    }
   ],
   "source": [
    "## SAME AS ABOVE BUT EDITED TO MERGE ALL OUTPUT FILES\n",
    "### THIS IS NOT WORKING!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of Excel files to process\n",
    "excel_files = [\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405584.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405587.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405591.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405595.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405598.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405602.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405606.xlsx',\n",
    "    'assets/quanthockey/xlsx/QuantHockey_1723405609.xlsx'\n",
    "]\n",
    "\n",
    "# List to hold the paths of the generated CSV files\n",
    "output_files = []\n",
    "\n",
    "# Loop through each file\n",
    "for file in excel_files:\n",
    "    # Step 1: Load the Excel file with multi-row headers\n",
    "    df = pd.read_excel(file, sheet_name='QuantHockey', header=[0, 1])\n",
    "\n",
    "    # Step 2: Flatten the multi-index columns by concatenating the two header rows\n",
    "    df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "    # Step 3: Add new columns titled 'season' and 'playoff' as the first two columns\n",
    "    df.insert(0, 'playoff', '2024')\n",
    "    df.insert(1, 'season', '2023')\n",
    "  \n",
    "\n",
    "    # Step 4: Construct the output CSV file name\n",
    "    output_file = file.replace('.xlsx', '_with_headers.csv')\n",
    "\n",
    "    # Step 5: Save the DataFrame to a CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Add the output file path to the list\n",
    "    output_files.append(output_file)\n",
    "\n",
    "    # Print confirmation\n",
    "    print(f\"The Excel file '{file}' has been processed and saved to '{output_file}' with new 'season' and 'playoff' columns.\")\n",
    "\n",
    "# Step 6: Merge all output CSV files into one DataFrame\n",
    "merged_df = pd.concat([pd.read_csv(f) for f in output_files], ignore_index=True)\n",
    "\n",
    "# Step 7: Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('assets/quanthockey/QuantHockey_2023_playoffs_merged.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"All processed CSV files have been merged and saved to 'assets/quanthockey/QuantHockey_2023_playoffs_merged.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (1) does not match length of index (1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m year \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Step 4: Add a new column titled 'season' as the first column and fill it with '2023'\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseason\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43myear\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Step 4: Save the DataFrame to a CSV file\u001b[39;00m\n\u001b[1;32m     19\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massets/quanthockey/quanthockey_\u001b[39m\u001b[38;5;132;01m{year}\u001b[39;00m\u001b[38;5;124mreg.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/git/NHL/myenv/lib/python3.9/site-packages/pandas/core/frame.py:5171\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   5169\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 5171\u001b[0m value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39minsert(loc, column, value, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[0;32m~/Documents/git/NHL/myenv/lib/python3.9/site-packages/pandas/core/frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/git/NHL/myenv/lib/python3.9/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1) does not match length of index (1000)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Excel file with multi-row headers\n",
    "excel_file = 'assets/quanthockey/xlsx/QuantHockey_1723404878.xlsx'\n",
    "\n",
    "# Step 2: Read the Excel file with the first two rows as headers\n",
    "df = pd.read_excel(excel_file, sheet_name='QuantHockey', header=[0, 1])\n",
    "\n",
    "# Step 3: Flatten the multi-index columns by concatenating the two header rows\n",
    "df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "# MY STEP: Define Year\n",
    "year = '2023'\n",
    "\n",
    "# Step 4: Add a new column titled 'season' as the first column and fill it with '2023'\n",
    "df.insert(0, 'season', {year})\n",
    "\n",
    "# Step 4: Save the DataFrame to a CSV file\n",
    "df.to_csv('assets/quanthockey/quanthockey_{year}reg.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"The Excel file with multi-row headers has been saved to 'assets/quanthockey/quanthockey_{year}reg'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Excel file with multi-row headers has been saved to 'assets/quanthockey/quanthockey_2023reg.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Excel file with multi-row headers\n",
    "excel_file = 'assets/quanthockey/xlsx/QuantHockey_1723404878.xlsx'\n",
    "\n",
    "# Step 2: Read the Excel file with the first two rows as headers\n",
    "df = pd.read_excel(excel_file, sheet_name='QuantHockey', header=[0, 1])\n",
    "\n",
    "# Step 3: Flatten the multi-index columns by concatenating the two header rows\n",
    "df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "# MY STEP: Define Year\n",
    "year = '2023'\n",
    "\n",
    "# Step 4: Add a new column titled 'season' as the first column and fill it with '2023'\n",
    "df.insert(0, 'season', [year] * len(df))\n",
    "\n",
    "# Step 5: Save the DataFrame to a CSV file\n",
    "df.to_csv(f'assets/quanthockey/quanthockey_{year}reg.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"The Excel file with multi-row headers has been saved to 'assets/quanthockey/quanthockey_{year}reg.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Excel file with multi-row headers has been saved to 'assets/quanthockey/quanthockey_reg2008.csv'.\n"
     ]
    }
   ],
   "source": [
    "## this block will be used to re-run the additional code for all remaining .xlsx files\n",
    "## NOTE the change in filepath\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Excel file with multi-row headers\n",
    "excel_file = 'assets/quanthockey/xlsx/QuantHockey_1723405107.xlsx'\n",
    "\n",
    "# Step 2: Read the Excel file with the first two rows as headers\n",
    "df = pd.read_excel(excel_file, sheet_name='QuantHockey', header=[0, 1])\n",
    "\n",
    "# Step 3: Flatten the multi-index columns by concatenating the two header rows\n",
    "df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "# MY STEP: Define Year\n",
    "year = '2008'\n",
    "\n",
    "# Step 4: Add a new column titled 'season' as the first column and fill it with '2023'\n",
    "df.insert(0, 'season', [year] * len(df))\n",
    "\n",
    "# Step 5: Save the DataFrame to a CSV file\n",
    "df.to_csv(f'assets/quanthockey/quanthockey_reg{year}.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"The Excel file with multi-row headers has been saved to 'assets/quanthockey/quanthockey_reg{year}.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files have been merged, sorted, and saved to 'assets/quanthockey/quanthockey_reg_all_sorted.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Step 1: Define the file path pattern to match all relevant CSV files\n",
    "file_pattern = 'assets/quanthockey/quanthockey_reg*.csv'\n",
    "\n",
    "# Step 2: Use glob to find all files that match the pattern\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "# Step 3: Merge all the CSV files into a single DataFrame\n",
    "merged_df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "\n",
    "# Step 4: Sort the DataFrame by 'season' (descending) and 'Unnamed: 0_level_0_Rk' (ascending)\n",
    "merged_df = merged_df.sort_values(by=['season', 'Unnamed: 0_level_0_Rk'], ascending=[False, True])\n",
    "\n",
    "# Step 5: Save the sorted DataFrame to a new CSV file\n",
    "merged_df.to_csv('assets/quanthockey/quanthockey_reg_all_sorted.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"All CSV files have been merged, sorted, and saved to 'assets/quanthockey/quanthockey_reg_all_sorted.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in the dataset:\n",
      "Empty DataFrame\n",
      "Columns: [season, Unnamed: 0_level_0_Rk, Unnamed: 1_level_0_Name, Overall NHL Stats_Team, Overall NHL Stats_Age, Overall NHL Stats_Pos, Overall NHL Stats_GP, Overall NHL Stats_G, Overall NHL Stats_A, Overall NHL Stats_P, Overall NHL Stats_PIM, Overall NHL Stats_+/-, Time on Ice_TOI, Time on Ice_ES, Time on Ice_PP, Time on Ice_SH, Goals_ESG, Goals_PPG, Goals_SHG, Goals_GWG, Goals_OTG, Assists_ESA, Assists_PPA, Assists_SHA, Assists_GWA, Assists_OTA, Points_ESP, Points_PPP, Points_SHP, Points_GWP, Points_OTP, Points_PPP%, per 60 All Situations_G/60, per 60 All Situations_A/60, per 60 All Situations_P/60, per 60 Even-Strength_ESG/60, per 60 Even-Strength_ESA/60, per 60 Even-Strength_ESP/60, per 60 Power-Play_PPG/60, per 60 Power-Play_PPA/60, per 60 Power-Play_PPP/60, per Game_G/GP, per Game_A/GP, per Game_P/GP, Shots_SHOTS, Shots_SH%, Defensive_HITS, Defensive_BS, Faceoffs_FOW, Faceoffs_FOL, Faceoffs_FO%]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 51 columns]\n",
      "Duplicates have been printed and saved to 'assets/quanthockey/quanthockey_reg_duplicates.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the merged and sorted CSV file\n",
    "df = pd.read_csv('assets/quanthockey/quanthockey_reg_all.csv')\n",
    "\n",
    "# Step 2: Identify duplicate rows\n",
    "# Keep all duplicates, not just the first occurrence\n",
    "duplicates = df[df.duplicated(keep=False)]\n",
    "\n",
    "# Step 3: Print the duplicate rows\n",
    "print(\"Duplicate rows in the dataset:\")\n",
    "print(duplicates)\n",
    "\n",
    "# Optional: Save the duplicates to a new CSV file if needed\n",
    "# duplicates.to_csv('assets/quanthockey/quanthockey_reg_duplicates.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Duplicates have been printed and saved to 'assets/quanthockey/quanthockey_reg_duplicates.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEGIN PLAYOFFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Excel file with multi-row headers has been saved to 'assets/quanthockey/quanthockey_playoff2016.csv'.\n"
     ]
    }
   ],
   "source": [
    "## code is taken from above and been adjusted to reflect playoff data\n",
    "## code updated to add second column with 'playoff in step 4\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Excel file with multi-row headers\n",
    "excel_file = 'assets/quanthockey/xlsx/QuantHockey_1723405249.xlsx'\n",
    "\n",
    "# Step 2: Read the Excel file with the first two rows as headers\n",
    "df = pd.read_excel(excel_file, sheet_name='QuantHockey', header=[0, 1])\n",
    "\n",
    "# Step 3: Flatten the multi-index columns by concatenating the two header rows\n",
    "df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "# MY STEP: Define Year\n",
    "year = '2016'\n",
    "\n",
    "# Step 4: Add a new column titled 'season' as the first column and 'playoff' as the second column\n",
    "df.insert(0, 'playoff', [str(int(year) + 1)] * len(df))  # Convert year to int, add 1, then convert back to string\n",
    "df.insert(1, 'season', [year] * len(df))  # 'season' column stays the same\n",
    "\n",
    "# Step 5: Save the DataFrame to a CSV file\n",
    "df.to_csv(f'assets/quanthockey/quanthockey_playoff{year}.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"The Excel file with multi-row headers has been saved to 'assets/quanthockey/quanthockey_playoff{year}.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files have been merged, sorted, and saved to 'assets/quanthockey/quanthockey_playoff_merged.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Step 1: Define the file path pattern to match all relevant CSV files\n",
    "file_pattern = 'assets/quanthockey/quanthockey_playoff*.csv'\n",
    "\n",
    "# Step 2: Use glob to find all files that match the pattern\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "# Step 3: Merge all the CSV files into a single DataFrame\n",
    "merged_df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "\n",
    "# Step 4: Sort the DataFrame by 'season' (descending) and 'Unnamed: 0_level_0_Rk' (ascending)\n",
    "merged_df = merged_df.sort_values(by=['season', 'Unnamed: 0_level_0_Rk'], ascending=[False, True])\n",
    "\n",
    "# Step 5: Save the sorted DataFrame to a new CSV file\n",
    "merged_df.to_csv('assets/quanthockey/quanthockey_playoff_merged.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"All CSV files have been merged, sorted, and saved to 'assets/quanthockey/quanthockey_playoff_merged.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
