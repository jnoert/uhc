{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://www.nhl.com/stats/teams?reportType=season&seasonFrom=20082009&seasonTo=20082009&gameType=2&sort=points,wins&page=0&pageSize=50\n",
    "method: per season export\n",
    "issues: no abbr, capital headings, long headings, season formatted '\n",
    "\n",
    "Legend\n",
    "Team: Team\n",
    "Season: Season\n",
    "GP: Games Played\n",
    "W: Wins\n",
    "L: Losses\n",
    "OT: Overtime Losses\n",
    "P: Points\n",
    "P%: Point Pctg\n",
    "RW: Regulation Wins (a Standings tiebreaker since 2019-20)\n",
    "ROW: Regulation Plus Overtime Wins (a Standings tiebreaker since 2010-11)\n",
    "S/O Win: Shootout Games Won (since 2005-06)\n",
    "GF: Goals For\n",
    "GA: Goals Against\n",
    "GF/GP: Goals For Per Game Played\n",
    "GA/GP: Goals Against Per Game Played\n",
    "PP%: Power Play Percentage\n",
    "PK%: Penalty Kill Percentage\n",
    "Net PP%: Power Play Net Pct\n",
    "Net PK%: Penalty Kill Net Pct\n",
    "Shots/GP: Shots For per Game\n",
    "SA/GP: Shots Against per Game\n",
    "FOW%: Face-off Win Percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'assets/nhldotcom/Summary.xlsx' has been transformed and saved as 'assets/nhldotcom/team_records_08.csv'.\n"
     ]
    }
   ],
   "source": [
    "#Python pandas, file 'assets/nhldotcom/Summary.xlsx' transorm into a .csv with the same path plus '/team_records_08'\n",
    "\n",
    "##\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Step 1: Load the Excel file\n",
    "excel_file = 'assets/nhldotcom/Summary.xlsx'\n",
    "\n",
    "# Step 2: Load the Excel sheet into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Step 3: Fix the 'Season' column by keeping only the first four digits\n",
    "if 'Season' in df.columns:\n",
    "    df['Season'] = df['Season'].astype(str).str[:4]\n",
    "\n",
    "# Step 3: Construct the new file path for the CSV\n",
    "# Split the original file path to get the directory\n",
    "directory = os.path.dirname(excel_file)\n",
    "\n",
    "# Construct the new path by appending '/team_records_08' to the directory\n",
    "csv_file = os.path.join(directory, 'team_records_08.csv')\n",
    "\n",
    "# Ensure the directory exists, if not, create it\n",
    "os.makedirs(os.path.dirname(csv_file), exist_ok=True)\n",
    "\n",
    "# Step 4: Save the DataFrame as a CSV file\n",
    "df.to_csv(csv_file, index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Excel file '{excel_file}' has been transformed and saved as '{csv_file}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python pandas\n",
    "There are a number of .xlsx files -- grab them with glob using 'assets/nhldotcom/xlsx/summary*.xlsx'\n",
    "Imprt each of these files in a new folder path 'assets/nhldotcom/csv/'\n",
    "Merge all csv files into one path 'assets/nhldotcom/teamstats.csv\n",
    "Make all headings lowercase\n",
    "In the 'season' column, keep only the first four digits of every entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Excel files have been processed and merged into 'assets/nhldotcom/teamstats.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Step 1: Define the file pattern to match all relevant Excel files\n",
    "file_pattern = 'assets/nhldotcom/xlsx/Summary*.xlsx'\n",
    "\n",
    "# Step 2: Use glob to find all files that match the pattern\n",
    "xlsx_files = glob.glob(file_pattern)\n",
    "\n",
    "# Step 3: Create a list to hold the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Step 4: Loop through each Excel file, convert it to CSV, and process it\n",
    "for file in xlsx_files:\n",
    "    # Load the Excel file into a DataFrame\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # Convert all column headings to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    # Fix the 'season' column to keep only the first four digits\n",
    "    if 'season' in df.columns:\n",
    "        df['season'] = df['season'].astype(str).str[:4]\n",
    "    \n",
    "    # Construct the new CSV file path\n",
    "    base_name = os.path.basename(file)\n",
    "    csv_file = os.path.join('assets/nhldotcom/csv/', base_name.replace('.xlsx', '.csv'))\n",
    "    \n",
    "    # Ensure the directory exists, if not, create it\n",
    "    os.makedirs(os.path.dirname(csv_file), exist_ok=True)\n",
    "    \n",
    "    # Save the DataFrame as a CSV file\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    \n",
    "    # Add the DataFrame to the list for later merging\n",
    "    dfs.append(df)\n",
    "\n",
    "# Step 5: Merge all DataFrames into one DataFrame\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 6: Save the merged DataFrame to a new CSV file\n",
    "merged_csv_file = 'assets/nhldotcom/teamstats.csv'\n",
    "merged_df.to_csv(merged_csv_file, index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"All Excel files have been processed and merged into '{merged_csv_file}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python pandas\n",
    "Task 1) compare file 'assets/nhldotcom/teamstats.csv' with 'assets/nhl_teams_abbreviations.csv' -- add a new column to 'teamstats.csv' as the second column in the table, title the column 'abbv' and for each row in that column cross-reference \"team\" between the 'teamstats.csv' file with the 'nhl_teams_abbreviations.csv' file and insert the 'Abbreviation\" into that cell\n",
    "Task 2) sort file by 'season' descending, secondary sort 'w'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'teamstats.csv' file has been updated with the 'abbv' column and sorted by 'season' and 'w'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Task 1: Add 'abbv' column to 'teamstats.csv'\n",
    "\n",
    "# Step 1: Load the CSV files\n",
    "teamstats_df = pd.read_csv('assets/nhldotcom/teamstats.csv')\n",
    "abbreviations_df = pd.read_csv('assets/nhl_teams_abbreviations.csv')\n",
    "\n",
    "# Step 2: Create a dictionary to map team names to abbreviations\n",
    "team_to_abbv = dict(zip(abbreviations_df['Team'], abbreviations_df['Abbreviation']))\n",
    "\n",
    "# Step 3: Add a new 'abbv' column to the teamstats DataFrame\n",
    "teamstats_df.insert(1, 'abbv', teamstats_df['team'].map(team_to_abbv))\n",
    "\n",
    "# Task 2: Sort the DataFrame by 'season' descending and 'w' ascending\n",
    "\n",
    "# Step 4: Sort the DataFrame\n",
    "teamstats_df = teamstats_df.sort_values(by=['season', 'w'], ascending=[False, True])\n",
    "\n",
    "# Step 5: Save the updated DataFrame back to the CSV file\n",
    "teamstats_df.to_csv('assets/nhldotcom/teamstats.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"The 'teamstats.csv' file has been updated with the 'abbv' column and sorted by 'season' and 'w'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "\t1.\tLoading the CSV Files:\n",
    "\t•\tteamstats_df = pd.read_csv('assets/nhldotcom/teamstats.csv'): Loads the teamstats.csv file.\n",
    "\t•\tabbreviations_df = pd.read_csv('assets/nhl_teams_abbreviations.csv'): Loads the nhl_teams_abbreviations.csv file.\n",
    "\t2.\tMapping Teams to Abbreviations:\n",
    "\t•\tteam_to_abbv = dict(zip(abbreviations_df['Team'], abbreviations_df['Abbreviation'])): Creates a dictionary where the keys are team names from the Team column and the values are abbreviations from the Abbreviation column.\n",
    "\t3.\tAdding the ‘abbv’ Column:\n",
    "\t•\tteamstats_df.insert(1, 'abbv', teamstats_df['team'].map(team_to_abbv)): Adds a new column named 'abbv' as the second column in the teamstats_df DataFrame. The map() function cross-references the team column in teamstats_df with the team_to_abbv dictionary to fill in the appropriate abbreviations.\n",
    "\t4.\tSorting the DataFrame:\n",
    "\t•\tteamstats_df = teamstats_df.sort_values(by=['season', 'w'], ascending=[False, True]): Sorts the DataFrame first by season in descending order and then by w (presumably wins) in ascending order.\n",
    "\t5.\tSaving the Updated DataFrame:\n",
    "\t•\tThe final DataFrame, with the new abbv column and sorted rows, is saved back to teamstats.csv.\n",
    "\t6.\tConfirmation:\n",
    "\t•\tA message is printed to confirm that the file has been updated and saved.\n",
    "\n",
    "Result:\n",
    "\n",
    "Running this script will update the teamstats.csv file by adding an abbv column with the corresponding team abbreviations, and it will sort the data by season (descending) and w (ascending). The updated file will overwrite the original teamstats.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python pandas\n",
    "Query 'assets/nhldotcom/teamstats.csv' and extract the number of rows with an integer in column 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '--'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massets/nhldotcom/teamstats.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Step 2: Check if the values in column 't' are integers\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# The .apply method with a lambda function and pd.to_numeric allows us to check if a value can be an integer\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m is_integer \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mto_numeric(x, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mnotnull() \u001b[38;5;241m&\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Step 3: Count the number of rows with an integer in column 't'\u001b[39;00m\n\u001b[1;32m     11\u001b[0m integer_count \u001b[38;5;241m=\u001b[39m df[is_integer]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/git/NHL/myenv/lib/python3.9/site-packages/pandas/core/series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/NHL/myenv/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/NHL/myenv/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Documents/git/NHL/myenv/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/NHL/myenv/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massets/nhldotcom/teamstats.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Step 2: Check if the values in column 't' are integers\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# The .apply method with a lambda function and pd.to_numeric allows us to check if a value can be an integer\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m is_integer \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mto_numeric(x, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mnotnull() \u001b[38;5;241m&\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mis_integer())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Step 3: Count the number of rows with an integer in column 't'\u001b[39;00m\n\u001b[1;32m     11\u001b[0m integer_count \u001b[38;5;241m=\u001b[39m df[is_integer]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '--'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "df = pd.read_csv('assets/nhldotcom/teamstats.csv')\n",
    "\n",
    "# Step 2: Check if the values in column 't' are integers\n",
    "# The .apply method with a lambda function and pd.to_numeric allows us to check if a value can be an integer\n",
    "is_integer = df['t'].apply(lambda x: pd.to_numeric(x, errors='coerce')).notnull() & df['t'].apply(lambda x: float(x).is_integer())\n",
    "\n",
    "# Step 3: Count the number of rows with an integer in column 't'\n",
    "integer_count = df[is_integer].shape[0]\n",
    "\n",
    "# Step 4: Print the result\n",
    "print(f\"Number of rows with an integer in column 't': {integer_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error you’re encountering is because there are values in the 't' column that cannot be converted to a float, such as the string '-'. To handle this, we can modify the approach to better manage non-numeric values.\n",
    "\n",
    "Here’s how you can adjust the code to correctly identify rows where the 't' column contains an integer:\n",
    "\n",
    "Updated Python Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with an integer in column 't': 175\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "df = pd.read_csv('assets/nhldotcom/teamstats.csv')\n",
    "\n",
    "# Step 2: Define a function to check if a value is an integer\n",
    "def is_integer(value):\n",
    "    try:\n",
    "        # Try to convert the value to a float, then check if it's an integer\n",
    "        return float(value).is_integer()\n",
    "    except ValueError:\n",
    "        # If conversion fails, the value is not a number\n",
    "        return False\n",
    "\n",
    "# Step 3: Apply the function to the 't' column and count the number of integer values\n",
    "integer_count = df['t'].apply(is_integer).sum()\n",
    "\n",
    "# Step 4: Print the result\n",
    "print(f\"Number of rows with an integer in column 't': {integer_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "\t1.\tDefine a Function to Check for Integers:\n",
    "\t•\tThe is_integer function tries to convert the value to a float and checks if it’s an integer using .is_integer(). If the conversion fails (e.g., because the value is '-' or some other non-numeric string), the function returns False.\n",
    "\t2.\tApply the Function:\n",
    "\t•\tdf['t'].apply(is_integer): This applies the is_integer function to each value in the 't' column. The result is a series of True or False values.\n",
    "\t3.\tCount the Integers:\n",
    "\t•\t.sum(): Summing the True values (which are treated as 1) gives the count of rows where the 't' column contains an integer.\n",
    "\t4.\tPrint the Result:\n",
    "\t•\tThe number of rows with an integer in the 't' column is printed.\n",
    "\n",
    "Result:\n",
    "\n",
    "This code should now correctly count the number of rows where the 't' column contains an integer, even in the presence of non-numeric values like '-'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add to the previous code a function that prints any 'season' where an integer exists in column 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with an integer in column 't': 175\n",
      "Seasons where 't' is an integer:\n",
      "2003\n",
      "2002\n",
      "2001\n",
      "2000\n",
      "1999\n",
      "1998\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "df = pd.read_csv('assets/nhldotcom/teamstats.csv')\n",
    "\n",
    "# Step 2: Define a function to check if a value is an integer\n",
    "def is_integer(value):\n",
    "    try:\n",
    "        # Try to convert the value to a float, then check if it's an integer\n",
    "        return float(value).is_integer()\n",
    "    except ValueError:\n",
    "        # If conversion fails, the value is not a number\n",
    "        return False\n",
    "\n",
    "# Step 3: Apply the function to the 't' column and count the number of integer values\n",
    "integer_count = df['t'].apply(is_integer).sum()\n",
    "\n",
    "# Step 4: Print the result\n",
    "print(f\"Number of rows with an integer in column 't': {integer_count}\")\n",
    "\n",
    "# Step 5: Filter the DataFrame for rows where 't' is an integer\n",
    "integer_rows = df[df['t'].apply(is_integer)]\n",
    "\n",
    "# Step 6: Print the unique 'season' values where 't' is an integer\n",
    "unique_seasons = integer_rows['season'].unique()\n",
    "print(\"Seasons where 't' is an integer:\")\n",
    "for season in unique_seasons:\n",
    "    print(season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "im deciding to omit 1) these years 2) the 't' column from my data entirely, as so much of my other team stat data only goes back to the 08/09 season. By removing these years from the data it will simplify edge cases caused by the string '--' that exists in those years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python pandas\n",
    "Query 'assets/nhldotcom/teamstats.csv' and duplicate this file, naming the new file 'assets/nhldotcom/teamstats(og).csv'\n",
    "In the original file 'assets/nhldotcom/teamstats.csv' I want to:\n",
    "1) remove column 't' \n",
    "2) delete all rows with 'season' equaling 1998, 1999, 2000, 2001, 2002, 2003\n",
    "Resave the file using the original path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original file 'assets/nhldotcom/teamstats.csv' has been backed up and modified. The 't' column was removed, and rows with seasons 1998-2003 were deleted.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the original CSV file\n",
    "original_file = 'assets/nhldotcom/teamstats.csv'\n",
    "df = pd.read_csv(original_file)\n",
    "\n",
    "# Step 2: Duplicate the file, saving it as 'assets/nhldotcom/teamstats(og).csv'\n",
    "backup_file = 'assets/nhldotcom/teamstats(og).csv'\n",
    "df.to_csv(backup_file, index=False)\n",
    "\n",
    "# Step 3: Remove the 't' column from the DataFrame\n",
    "df = df.drop(columns=['t'])\n",
    "\n",
    "# Step 4: Delete all rows where 'season' equals 1998, 1999, 2000, 2001, 2002, 2003\n",
    "df = df[~df['season'].isin([1998, 1999, 2000, 2001, 2002, 2003])]\n",
    "\n",
    "# Step 5: Save the modified DataFrame back to the original file path\n",
    "df.to_csv(original_file, index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Original file '{original_file}' has been backed up and modified. The 't' column was removed, and rows with seasons 1998-2003 were deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'assets/nhldotcom/teamstats_champ.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove the specified columns\n",
    "df = df.drop(columns=['playoff', 'full', 'coach'])\n",
    "\n",
    "# Save the modified DataFrame back to the same file\n",
    "df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
