{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    playoff  season                  full team           coach\n",
      "0      2024    2023      Florida Panthers  FLA    Paul Maurice\n",
      "1      2023    2022  Vegas Golden Knights  VGK   Bruce Cassidy\n",
      "2      2022    2021    Colorado Avalanche  COL    Jared Bednar\n",
      "3      2021    2020   Tampa Bay Lightning  TBL      Jon Cooper\n",
      "4      2020    2019   Tampa Bay Lightning  TBL      Jon Cooper\n",
      "..      ...     ...                   ...  ...             ...\n",
      "93     1931    1930    Montreal Canadiens  MTL      Cecil Hart\n",
      "94     1930    1929    Montreal Canadiens  MTL      Cecil Hart\n",
      "95     1929    1928         Boston Bruins  BOS        Art Ross\n",
      "96     1928    1927      New York Rangers  NYR  Lester Patrick\n",
      "97     1927    1926       Ottawa Senators  OTT     George Gill\n",
      "\n",
      "[98 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "##test\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "df = pd.read_csv('assets/nhl_champions.csv')\n",
    "\n",
    "# Step 2: Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ten largest numerical values in the DataFrame are:\n",
      "370  iceTime    308162.0\n",
      "41   iceTime    306407.0\n",
      "487  iceTime    304392.0\n",
      "389  iceTime    303509.0\n",
      "569  iceTime    302226.0\n",
      "23   iceTime    301956.0\n",
      "48   iceTime    301952.0\n",
      "278  iceTime    301838.0\n",
      "204  iceTime    301586.0\n",
      "395  iceTime    301584.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from 'assets/team_stats_complete_wip.csv'\n",
    "asset1 = pd.read_csv('assets/team_stats_complete_wip.csv')\n",
    "\n",
    "# Find the ten largest numerical values in the DataFrame\n",
    "largest_values = asset1.select_dtypes(include=[float, int]).stack().nlargest(10)\n",
    "\n",
    "# Display the ten largest values\n",
    "print(\"The ten largest numerical values in the DataFrame are:\")\n",
    "print(largest_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ten largest numerical values in the DataFrame are:\n",
      "3  iceTime                              283913.261062\n",
      "0  iceTime                              282977.312500\n",
      "2  iceTime                              282743.718750\n",
      "1  iceTime                              282058.250000\n",
      "0  scoreAdjustedShotsAttemptsFor          4638.966250\n",
      "1  scoreAdjustedShotsAttemptsFor          4601.880000\n",
      "0  shotAttemptsFor                        4586.937500\n",
      "1  shotAttemptsFor                        4568.500000\n",
      "3  scoreAdjustedShotsAttemptsAgainst      4559.909646\n",
      "   shotAttemptsAgainst                    4521.884956\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from 'assets/team_stats_complete_wip.csv'\n",
    "asset1 = pd.read_csv('assets/means.csv')\n",
    "\n",
    "# Find the ten largest numerical values in the DataFrame\n",
    "largest_values = asset1.select_dtypes(include=[float, int]).stack().nlargest(10)\n",
    "\n",
    "# Display the ten largest values\n",
    "print(\"The ten largest numerical values in the DataFrame are:\")\n",
    "print(largest_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of unique values in column 204:\n",
      "_merge\n",
      "both          13564\n",
      "left_only       861\n",
      "right_only      859\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "file_path = 'assets/skaters_quanthockey_merged.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Query column 204\n",
    "column_204 = df.iloc[:, 203]  # Use iloc to select column 204 (indexing starts from 0, so 203 is the 204th column)\n",
    "\n",
    "# Step 3: Count the number of rows with each unique value in column 204\n",
    "value_counts = column_204.value_counts()\n",
    "\n",
    "# Step 4: Print the counts\n",
    "print(f\"Counts of unique values in column 204:\\n{value_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of unique values in column 204 considering unique names:\n",
      "_merge\n",
      "both          2646\n",
      "left_only      213\n",
      "right_only     182\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "file_path = 'assets/skaters_quanthockey_merged.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Drop duplicates based on the 'name' column to ensure uniqueness\n",
    "df_unique = df.drop_duplicates(subset='name')\n",
    "\n",
    "# Step 3: Query column 204 from the unique names DataFrame\n",
    "column_204 = df_unique.iloc[:, 203]  # Use iloc to select column 204 (indexing starts from 0, so 203 is the 204th column)\n",
    "\n",
    "# Step 4: Count the number of rows with each unique value in column 204\n",
    "value_counts = column_204.value_counts()\n",
    "\n",
    "# Step 5: Print the counts\n",
    "print(f\"Counts of unique values in column 204 considering unique names:\\n{value_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered results have been saved to 'assets/filtered_names_left_right_only.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "file_path = 'assets/skaters_quanthockey_merged.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Drop duplicates based on the 'name' column to ensure uniqueness\n",
    "df_unique = df.drop_duplicates(subset='name')\n",
    "\n",
    "# Step 3: Query column 204 and filter rows where the result matches 'left_only' or 'right_only'\n",
    "column_204 = df_unique.iloc[:, 203]  # Use iloc to select column 204 (indexing starts from 0, so 203 is the 204th column)\n",
    "filtered_df = df_unique[(column_204 == 'left_only') | (column_204 == 'right_only')]\n",
    "\n",
    "# Step 4: Save the filtered DataFrame to a new CSV file, including 'name' and 'column 204'\n",
    "output_file = 'assets/filtered_names_left_right_only.csv'\n",
    "filtered_df[['name', column_204.name]].to_csv(output_file, index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Filtered results have been saved to '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered and sorted results have been saved to 'assets/filtered_names_left_right_only_sorted.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "file_path = 'assets/skaters_quanthockey_merged.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Drop duplicates based on the 'name' column to ensure uniqueness\n",
    "df_unique = df.drop_duplicates(subset='name')\n",
    "\n",
    "# Step 3: Query column 204 and filter rows where the result matches 'left_only' or 'right_only'\n",
    "column_204 = df_unique.iloc[:, 203]  # Use iloc to select column 204 (indexing starts from 0, so 203 is the 204th column)\n",
    "filtered_df = df_unique[(column_204 == 'left_only') | (column_204 == 'right_only')]\n",
    "\n",
    "# Step 4: Sort the filtered DataFrame by the second column (column 204) and then by the first column ('name')\n",
    "filtered_df_sorted = filtered_df.sort_values(by=[column_204.name, 'name'])\n",
    "\n",
    "# Step 5: Save the sorted DataFrame to a new CSV file, including 'name' and 'column 204'\n",
    "output_file = 'assets/filtered_names_left_right_only_sorted.csv'\n",
    "filtered_df_sorted[['name', column_204.name]].to_csv(output_file, index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Filtered and sorted results have been saved to '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The creation timestamp for assets/updated_asset.csv in Mountain Time is: 2024-08-14 01:11:46.020879-06:00\n",
      "The file was created 11.52 hours ago.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# File path\n",
    "file_path = 'assets/updated_asset.csv'\n",
    "\n",
    "# Get the creation timestamp\n",
    "creation_time = os.path.getctime(file_path)\n",
    "\n",
    "# Convert to a UTC datetime object\n",
    "creation_time_utc = datetime.fromtimestamp(creation_time, pytz.utc)\n",
    "\n",
    "# Convert to Mountain Time\n",
    "mountain_time = creation_time_utc.astimezone(pytz.timezone('America/Denver'))\n",
    "\n",
    "# Get current time in Mountain Time\n",
    "current_time = datetime.now(pytz.timezone('America/Denver'))\n",
    "\n",
    "# Calculate the difference in hours\n",
    "time_difference = current_time - mountain_time\n",
    "hours_ago = time_difference.total_seconds() / 3600\n",
    "\n",
    "# Load the CSV file with pandas (optional)\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Output the creation time in Mountain Time and how many hours ago it was created\n",
    "print(f\"The creation timestamp for {file_path} in Mountain Time is: {mountain_time}\")\n",
    "print(f\"The file was created {hours_ago:.2f} hours ago.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
